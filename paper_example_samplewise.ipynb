{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Example sample-wise adaptation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from numpy import unravel_index\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import preprocessing\n",
    "import ot\n",
    "import scipy.io\n",
    "import mne          \n",
    "from mne.decoding import CSP\n",
    "mne.set_log_level(verbose='warning') #to avoid info at terminal\n",
    "import matplotlib.pyplot as pl\n",
    "from random import seed\n",
    "seed(30)\n",
    "from MIOTDAfunctions import*\n",
    "\n",
    "# get the functions from RPA package\n",
    "import rpa.transfer_learning as TL\n",
    "\n",
    "from pyriemann.classification import MDM\n",
    "from pyriemann.estimation import Covariances\n",
    "from pyriemann.utils.base import invsqrtm\n",
    "import timeit\n",
    "\n",
    "#ignore warning \n",
    "from warnings import simplefilter\n",
    "\n",
    "# ignore all future warnings\n",
    "simplefilter(action='ignore', category=FutureWarning)\n",
    "simplefilter(action='ignore', category=UserWarning)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Methods definition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def SC(Gte, Yte, lda):\n",
    "    \n",
    "    start = timeit.default_timer()\n",
    "    \n",
    "    yt_predict = lda.predict(Gte)\n",
    "    \n",
    "    stop = timeit.default_timer()\n",
    "    time = stop - start\n",
    "    \n",
    "    return yt_predict, time "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def SR(Data_S2, Labels_S2, re, Xtr, Ytr, Xte, Yte):\n",
    "    \n",
    "    start = timeit.default_timer()\n",
    "    \n",
    "    #Get Data\n",
    "    Xtr2add = Data_S2[0:20*re+20]\n",
    "    Ytr2add = Labels_S2[0:20*re+20]\n",
    "    \n",
    "    Xtr2 = np.vstack(((Xtr, Xtr2add)))\n",
    "    Ytr2 = np.hstack(((Ytr, Ytr2add)))\n",
    "        \n",
    "    Ytr2 = Ytr2[len(Ytr2add):]\n",
    "    Xtr2 = Xtr2[len(Ytr2add):]\n",
    "\n",
    "    # Create a new CSP\n",
    "    csp = CSP(n_components=6, reg='empirical', log=True, norm_trace=False, cov_est='epoch')\n",
    "    \n",
    "    #learn new csp filters\n",
    "    Gtr = csp.fit_transform(Xtr2,Ytr2)\n",
    "    \n",
    "    #learn new lda\n",
    "    lda = LinearDiscriminantAnalysis()\n",
    "    lda.fit(Gtr,Ytr2)\n",
    "\n",
    "    # Apply on new test data\n",
    "    Gte = csp.transform(Xte)\n",
    "    #ldatest\n",
    "    yt_predict = lda.predict(Gte)\n",
    "    \n",
    "    # time\n",
    "    stop = timeit.default_timer()\n",
    "    time = stop - start\n",
    "    \n",
    "    return yt_predict, time "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Sinkhorn_Transport(Gtr_daot, Ytr_daot, regu_, Gtr, Ytr, Gval, Gte, lda, metric, outerkfold, innerkfold, M):\n",
    "    \n",
    "    \n",
    "    #time\n",
    "    start = timeit.default_timer()\n",
    "        \n",
    "    otda = ot.da.SinkhornTransport(metric=metric, reg_e=regu_)\n",
    "    #learn the map\n",
    "    otda.fit(Xs=Gtr_daot, ys=Ytr_daot, Xt=Gval)\n",
    "    \n",
    "    #apply the mapping over source data\n",
    "    transp_Xs = otda.transform(Xs=Gtr)\n",
    "\n",
    "    # train a new classifier bases upon the transform source data\n",
    "    lda.fit(transp_Xs, Ytr)\n",
    "    \n",
    "    # Compute acc\n",
    "    yt_predict = lda.predict(Gte)\n",
    "    \n",
    "    # time\n",
    "    stop = timeit.default_timer()\n",
    "    time = stop - start  \n",
    "    \n",
    "    return yt_predict, time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def GroupLasso_Transport(Gtr_daot, Ytr_daot, regu_, Gtr, Ytr, Gval, Gte, lda, metric, outerkfold, innerkfold, M):\n",
    "        \n",
    "    #time\n",
    "    start = timeit.default_timer()\n",
    "    \n",
    "        \n",
    "    otda = ot.da.SinkhornL1l2Transport(metric = metric ,reg_e = regu_[0], reg_cl = regu_[1])\n",
    "    otda.fit(Xs=Gtr_daot, ys=Ytr_daot, Xt=Gval)\n",
    "\n",
    "    #transport taget samples onto source samples\n",
    "    transp_Xs = otda.transform(Xs=Gtr)\n",
    "\n",
    "    # train a new classifier bases upon the transform source data\n",
    "    lda.fit(transp_Xs, Ytr)\n",
    "\n",
    "    # Compute acc\n",
    "    yt_predict = lda.predict(Gte)   \n",
    "    # time\n",
    "    stop = timeit.default_timer()\n",
    "    time = stop - start \n",
    "        \n",
    "    \n",
    "    return yt_predict, time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Backward_Sinkhorn_Transport(Gtr_daot, Ytr_daot, regu_, Gtr, Ytr, Gval, Gte, lda, metric, outerkfold, innerkfold, M):\n",
    "   \n",
    "    # time\n",
    "    start = timeit.default_timer()\n",
    "      \n",
    "    # Transport plan\n",
    "    botda = ot.da.SinkhornTransport(metric=metric, reg_e=regu_)\n",
    "    botda.fit(Xs=Gval, ys=Yval, Xt=Gtr_daot)\n",
    "    \n",
    "    #transport testing samples\n",
    "    transp_Xt_backward = botda.transform(Xs=Gte)\n",
    "    \n",
    "    # Compute accuracy without retraining    \n",
    "    yt_predict = lda.predict(transp_Xt_backward)\n",
    "    \n",
    "    # time\n",
    "    stop = timeit.default_timer()\n",
    "    time = stop - start\n",
    "    \n",
    "    return yt_predict, time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Backward_GroupLasso_Transport(Gtr_daot, Ytr_daot, regu_, Gtr, Ytr, Gval, Gte, lda, metric, outerkfold, innerkfold, M):\n",
    "       \n",
    "    #time\n",
    "    start = timeit.default_timer()\n",
    "      \n",
    "    botda = ot.da.SinkhornL1l2Transport(metric=metric, reg_e=regu_[0], reg_cl=regu_[1])\n",
    "    botda.fit(Xs=Gval, ys=Yval, Xt=Gtr_daot)\n",
    "    \n",
    "    #transport testing samples\n",
    "    transp_Xt_backward=botda.transform(Xs=Gte)\n",
    "    \n",
    "    # Compute accuracy without retraining    \n",
    "    yt_predict = lda.predict(transp_Xt_backward)\n",
    "    \n",
    "    # time\n",
    "    stop = timeit.default_timer()\n",
    "    time = stop - start\n",
    "    \n",
    "    \n",
    "    return yt_predict, time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def RPA(Xtr, Xval, Xte, Ytr, Yval, Yte):\n",
    "    \n",
    "    # time\n",
    "    start = timeit.default_timer()\n",
    "    # cov matrix estimation\n",
    "    cov_tr = Covariances().transform(Xtr)\n",
    "    cov_val= Covariances().transform(Xval)\n",
    "    cov_te = Covariances().transform(Xte)\n",
    "        \n",
    "    clf = MDM()\n",
    "    source={'covs':cov_tr, 'labels': Ytr}\n",
    "    target_org_train={'covs':cov_val, 'labels': Yval}\n",
    "    target_org_test={'covs':cov_te, 'labels': Yte}\n",
    "    \n",
    "    # re-centered matrices\n",
    "    source_rct, target_rct_train, target_rct_test = TL.RPA_recenter(source, target_org_train, target_org_test)   \n",
    "    # stretched the re-centered matrices\n",
    "    source_rcs, target_rcs_train, target_rcs_test = TL.RPA_stretch(source_rct, target_rct_train, target_rct_test)\n",
    "    # rotate the re-centered-stretched matrices using information from classes\n",
    "    source_rpa, target_rpa_train, target_rpa_test = TL.RPA_rotate(source_rcs, target_rcs_train, target_rcs_test)\n",
    "    \n",
    "    # get data\n",
    "    covs_source, y_source = source_rpa['covs'], source_rpa['labels']\n",
    "    covs_target_train, y_target_train = target_rpa_train['covs'], target_rpa_train['labels']\n",
    "    covs_target_test, y_target_test = target_rpa_test['covs'], target_rpa_test['labels']\n",
    "    \n",
    "    # append train and validation data\n",
    "    covs_train = np.concatenate([covs_source, covs_target_train])\n",
    "    y_train = np.concatenate([y_source, y_target_train])\n",
    "    \n",
    "    # train\n",
    "    clf.fit(covs_train, y_train)\n",
    "    \n",
    "    # test\n",
    "    covs_test = covs_target_test\n",
    "    y_test = y_target_test\n",
    "    yt_predict = clf.predict(covs_test)\n",
    "    \n",
    "    # time\n",
    "    stop = timeit.default_timer()\n",
    "    time = stop - start\n",
    "    \n",
    "    return yt_predict, time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def EU(Xtr,Xval,Xte,Ytr,Yval,Yte):\n",
    "    \n",
    "    # time\n",
    "    start = timeit.default_timer()\n",
    "    # Estimate single trial covariance\n",
    "    cov_tr = Covariances().transform(Xtr)\n",
    "    cov_val= Covariances().transform(Xval)\n",
    "    \n",
    "    Ctr = cov_tr.mean(0)\n",
    "    Cval = cov_val.mean(0)\n",
    "    \n",
    "    # aligment\n",
    "    Xtr_eu = np.asarray([np.dot(invsqrtm(Ctr), epoch) for epoch in Xtr])\n",
    "    Xval_eu = np.asarray([np.dot(invsqrtm(Cval), epoch) for epoch in Xval])\n",
    "    Xte_eu = np.asarray([np.dot(invsqrtm(Cval), epoch) for epoch in Xte])\n",
    "\n",
    "    # append train and validation data\n",
    "    x_train = np.concatenate([Xtr_eu, Xval_eu])\n",
    "    y_train = np.concatenate([Ytr, Yval])\n",
    "\n",
    "    # train new csp+lda\n",
    "    csp = CSP(n_components=6, reg='empirical', log=True, norm_trace=False, cov_est='epoch')\n",
    "    # learn csp filters\n",
    "    Gtr = csp.fit_transform(x_train,y_train)\n",
    "    \n",
    "    # learn lda\n",
    "    lda = LinearDiscriminantAnalysis()\n",
    "    lda.fit(Gtr,y_train)\n",
    "    \n",
    "    # test\n",
    "    Gte = csp.transform(Xte_eu)  \n",
    "    # acc\n",
    "    yt_predict = lda.predict(Gte)\n",
    "    \n",
    "    # time\n",
    "    stop = timeit.default_timer()\n",
    "    time = stop - start\n",
    "        \n",
    "    return yt_predict, time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### OTDA params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "rango_cl=[0.1, 1, 10]\n",
    "rango_e=[0.1, 1, 10] \n",
    "metric = 'sqeuclidean'\n",
    "outerkfold = 20\n",
    "innerkfold = None\n",
    "M=20"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load and filter data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "fName = 'Data/DataSession1_S9.mat'\n",
    "s = scipy.io.loadmat(fName)\n",
    "\n",
    "Data_S1=s[\"X\"]\n",
    "Labels_S1=s[\"y\"]\n",
    "Labels_S1=np.squeeze(Labels_S1)\n",
    "\n",
    "#filterting with mne\n",
    "[nt, nc, ns]=np.shape(Data_S1)\n",
    "Data_S1=np.reshape(Data_S1, [nt, nc*ns])\n",
    "Data_S1=mne.filter.filter_data(Data_S1, 128, 8, 30)\n",
    "Data_S1=np.reshape(Data_S1, [nt,nc,ns])\n",
    "\n",
    "fName = 'Data/DataSession2_S9.mat'\n",
    "s2 = scipy.io.loadmat(fName)\n",
    "\n",
    "Data_S2=s2[\"X\"]\n",
    "Labels_S2=s2[\"y\"]\n",
    "Labels_S2=np.squeeze(Labels_S2)\n",
    "\n",
    "#filterting with mne\n",
    "[nt, nc, ns]=np.shape(Data_S2)\n",
    "Data_S2=np.reshape(Data_S2, [nt, nc*ns])\n",
    "Data_S2=mne.filter.filter_data(Data_S2, 128, 8, 30)\n",
    "Data_S2=np.reshape(Data_S2, [nt,nc,ns])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define variables to save the predictions\n",
    "yt_predict_sc=[]\n",
    "yt_predict_sr=[]\n",
    "yt_predict_1=[]\n",
    "yt_predict_2=[]\n",
    "yt_predict_3=[]\n",
    "yt_predict_4=[]\n",
    "yt_predict_rpa=[]\n",
    "yt_predict_eu=[]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Learn CSP+LDA from source data (Data_S1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LinearDiscriminantAnalysis(n_components=None, priors=None, shrinkage=None,\n",
       "                           solver='svd', store_covariance=False, tol=0.0001)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Xtr = Data_S1\n",
    "Ytr = Labels_S1\n",
    "csp = CSP(n_components=6, reg='empirical', log=True, norm_trace=False, cov_est='epoch')\n",
    "#learn csp filters\n",
    "Gtr = csp.fit_transform(Xtr, Ytr)\n",
    "#learn lda\n",
    "lda = LinearDiscriminantAnalysis()\n",
    "lda.fit(Gtr,Ytr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Use the first 20 trials as the validation set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "Labels_te=Labels_S2[20:]\n",
    "##\n",
    "Xval=Data_S2[0:20]\n",
    "Yval=Labels_S2[0:20]\n",
    "##\n",
    "Gval=csp.transform(Xval)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### select source subset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "#for fotda, create a new classifier (clf)\n",
    "clf=LinearDiscriminantAnalysis()\n",
    "G_FOTDAs_, Y_FOTDAs_, regu_FOTDAs_=\\\n",
    "SelectSubsetTraining_OTDAs(Gtr, Ytr, Gval, Yval, rango_e, clf, metric, outerkfold, innerkfold, M)\n",
    "G_FOTDAl1l2_, Y_FOTDAl1l2_, regu_FOTDAl1l2_=\\\n",
    "    SelectSubsetTraining_OTDAl1l2(Gtr, Ytr, Gval, Yval, rango_e, rango_cl, clf, metric, outerkfold, innerkfold, M)\n",
    "#for botda, use the already trained classifier (lda)\n",
    "G_BOTDAs_, Y_BOTDAs_, regu_BOTDAs_=\\\n",
    "SelectSubsetTraining_BOTDAs(Gtr, Ytr, Gval, Yval, rango_e, lda, metric, outerkfold, innerkfold, M)\n",
    "G_BOTDAl1l2_, Y_BOTDAl1l2_, regu_BOTDAl1l2_=\\\n",
    "SelectSubsetTraining_BOTDAl1l2(Gtr, Ytr, Gval, Yval, rango_e, rango_cl, lda, metric, outerkfold, innerkfold, M)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### For each sample, make the data adaptation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running testing trial=10\n",
      "Running testing trial=20\n",
      "Running testing trial=30\n",
      "Running testing trial=40\n",
      "Running testing trial=50\n",
      "Running testing trial=60\n",
      "Running testing trial=70\n",
      "Running testing trial=80\n",
      "Running testing trial=90\n",
      "Running testing trial=100\n",
      "Running testing trial=110\n",
      "Running testing trial=120\n",
      "Running testing trial=130\n",
      "Running testing trial=140\n"
     ]
    }
   ],
   "source": [
    "for re in range(1,len(Labels_te)+1):\n",
    "    if np.mod(re,10)==0 : print('Running testing trial={:1.0f}'.format(re))\n",
    "    #testing trial\n",
    "    Xte=Data_S2[20+(re-1):20+(re)]\n",
    "    Xte=Xte.reshape(1, nc, ns)\n",
    "    Yte=Labels_S2[20+(re-1):20+(re)]\n",
    "    \n",
    "    Xval=np.vstack((Xval, Xte))\n",
    "    Yval=np.hstack((Yval, Yte))\n",
    "    \n",
    "    #csp estimation\n",
    "    Gval=csp.transform(Xval)\n",
    "    Gte=csp.transform(Xte)\n",
    "         \n",
    "    # SC  \n",
    "    yt_predict, time_sc = SC(Gte, Yte, lda)\n",
    "    yt_predict_sc.append(yt_predict)\n",
    "\n",
    "    \n",
    "    # SR\n",
    "    yt_predict, time_sr = SR(Data_S2, Labels_S2, re, Xtr, Ytr, Xte, Yte)\n",
    "    yt_predict_sr.append(yt_predict)\n",
    "\n",
    "    #%% # Sinkhorn Transport\n",
    "    yt_predict, time_fs = Sinkhorn_Transport(G_FOTDAs_, Y_FOTDAs_, regu_FOTDAs_, Gtr, Ytr, Gval, Gte, clf, metric, outerkfold, innerkfold, M)\n",
    "    yt_predict_1.append(yt_predict)\n",
    "\n",
    "    #%% # Group-Lasso Transport\n",
    "    yt_predict, time_fg = GroupLasso_Transport(G_FOTDAl1l2_, Y_FOTDAl1l2_, regu_FOTDAl1l2_, Gtr, Ytr, Gval, Gte, clf, metric, outerkfold, innerkfold, M)\n",
    "    yt_predict_2.append(yt_predict)\n",
    "\n",
    "    #%% # Backward Sinkhorn Transport\n",
    "    yt_predict, time_bs = Backward_Sinkhorn_Transport(G_BOTDAs_, Y_BOTDAs_, regu_BOTDAs_, Gtr, Ytr, Gval, Gte, lda, metric, outerkfold, innerkfold, M)\n",
    "    yt_predict_3.append(yt_predict)\n",
    "\n",
    "    #%% # Backward Group-Lasso Transport\n",
    "    yt_predict, time_bg = Backward_GroupLasso_Transport(G_BOTDAl1l2_, Y_BOTDAl1l2_, regu_BOTDAl1l2_, Gtr, Ytr, Gval, Gte, lda, metric, outerkfold, innerkfold, M)\n",
    "    yt_predict_4.append(yt_predict)\n",
    "\n",
    "    # Riemann\n",
    "    yt_predict, time_rpa = RPA(Xtr,Xval,Xte,Ytr,Yval,Yte)\n",
    "    yt_predict_rpa.append(yt_predict)\n",
    "\n",
    "    # Euclidean\n",
    "    yt_predict, time_eu = EU(Xtr,Xval,Xte,Ytr,Yval,Yte)\n",
    "    yt_predict_eu.append(yt_predict)\n",
    "    \n",
    "    #save times\n",
    "    times = [time_sr, time_rpa, time_eu, time_fs, time_fg, time_bs, time_bg]\n",
    "        \n",
    "    if re==1:\n",
    "        times_se = times\n",
    "    else:\n",
    "        times_se = np.vstack((times_se, times))  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ACC\n",
      "{'sc': 0.7214285714285714, 'sr': 0.8571428571428571, 'fotda_s': 0.7857142857142857, 'fotda_l1l2': 0.7642857142857142, 'botda_s': 0.7928571428571428, 'botda_l1l2': 0.9857142857142858}\n",
      "CT\n",
      "{'sr': 1.159, 'rpa': 4.12, 'eu': 1.988, 'fotda_s': 0.013, 'fotda_l1l2': 0.29, 'botda_s': 0.012, 'botda_l1l2': 0.123}\n"
     ]
    }
   ],
   "source": [
    "# compute accuracy \n",
    "yt_predict_4=np.squeeze(np.asarray(yt_predict_4))\n",
    "yt_predict_3=np.squeeze(np.asarray(yt_predict_3))\n",
    "yt_predict_2=np.squeeze(np.asarray(yt_predict_2))\n",
    "yt_predict_1=np.squeeze(np.asarray(yt_predict_1))\n",
    "yt_predict_sc=np.squeeze(np.asarray(yt_predict_sc))\n",
    "yt_predict_sr=np.squeeze(np.asarray(yt_predict_sr))\n",
    "\n",
    "acc_botdal1l2=accuracy_score(Labels_te, yt_predict_4)\n",
    "acc_botdas=accuracy_score(Labels_te, yt_predict_3)\n",
    "acc_fotdal1l2=accuracy_score(Labels_te, yt_predict_2)\n",
    "acc_fotdas=accuracy_score(Labels_te, yt_predict_1)\n",
    "acc_sc=accuracy_score(Labels_te, yt_predict_sc)\n",
    "acc_sr=accuracy_score(Labels_te, yt_predict_sr)\n",
    "\n",
    "#print accuracy\n",
    "acc={}\n",
    "acc[\"sc\"]=acc_sc\n",
    "acc[\"sr\"]=acc_sr\n",
    "acc[\"fotda_s\"]=acc_fotdas\n",
    "acc[\"fotda_l1l2\"]=acc_fotdal1l2\n",
    "acc[\"botda_s\"]=acc_botdas\n",
    "acc[\"botda_l1l2\"]=acc_botdal1l2\n",
    "    \n",
    "\n",
    "#print computing time\n",
    "mean_time = np.mean(times_se, axis=0)\n",
    "time = {}\n",
    "time[\"sr\"] = round(mean_time[0],3)\n",
    "time[\"rpa\"] = round(mean_time[1],3)\n",
    "time[\"eu\"] = round(mean_time[2],3)\n",
    "time[\"fotda_s\"] = round(mean_time[3],3)\n",
    "time[\"fotda_l1l2\"] = round(mean_time[4],3)\n",
    "time[\"botda_s\"] = round(mean_time[5],3)\n",
    "time[\"botda_l1l2\"] = round(mean_time[6],3)\n",
    "    \n",
    "print('ACC')\n",
    "print(acc)\n",
    "print('CT')\n",
    "print(time)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
