{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Example block-wise adaptation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from numpy import unravel_index\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import preprocessing\n",
    "import ot\n",
    "import scipy.io\n",
    "import mne          \n",
    "from mne.decoding import CSP\n",
    "mne.set_log_level(verbose='warning') #to avoid info at terminal\n",
    "import matplotlib.pyplot as pl\n",
    "from random import seed\n",
    "seed(30)\n",
    "from MIOTDAfunctions import*\n",
    "\n",
    "# get the functions from RPA package\n",
    "import rpa.transfer_learning as TL\n",
    "\n",
    "from pyriemann.classification import MDM\n",
    "from pyriemann.estimation import Covariances\n",
    "from pyriemann.utils.base import invsqrtm\n",
    "import timeit\n",
    "\n",
    "#ignore warning \n",
    "from warnings import simplefilter\n",
    "\n",
    "# ignore all future warnings\n",
    "simplefilter(action='ignore', category=FutureWarning)\n",
    "simplefilter(action='ignore', category=UserWarning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_acc=[]\n",
    "results_all=[]\n",
    "results_all_inv=[]\n",
    "\n",
    "rango_cl = [0.1, 0.5, 1, 2, 5, 10, 20]\n",
    "rango_e = [0.1, 0.5, 1, 2, 5, 10, 20]\n",
    "metric = 'sqeuclidean'\n",
    "outerkfold = 10 # for faster online computation select a lower value\n",
    "innerkfold = dict(nfold=10, train_size=0.8)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Methods definition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def SC(Gte, Yte, lda):\n",
    "    \n",
    "    start = timeit.default_timer()\n",
    "    \n",
    "    acc = lda.score(Gte, Yte)\n",
    "    \n",
    "    stop = timeit.default_timer()\n",
    "    time = stop - start\n",
    "    \n",
    "    return acc, time "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def SR(Data_S2, Labels_S2, re, Xtr, Ytr, Xte, Yte):\n",
    "    \n",
    "    start = timeit.default_timer()\n",
    "    \n",
    "    #Get Data\n",
    "    Xtr2add = Data_S2[0:20*re+20]\n",
    "    Ytr2add = Labels_S2[0:20*re+20]\n",
    "    \n",
    "    Xtr2 = np.vstack(((Xtr, Xtr2add)))\n",
    "    Ytr2 = np.hstack(((Ytr, Ytr2add)))\n",
    "        \n",
    "    Ytr2 = Ytr2[len(Ytr2add):]\n",
    "    Xtr2 = Xtr2[len(Ytr2add):]\n",
    "\n",
    "    # Create a new CSP\n",
    "    csp = CSP(n_components=6, reg='empirical', log=True, norm_trace=False, cov_est='epoch')\n",
    "    \n",
    "    #learn new csp filters\n",
    "    Gtr = csp.fit_transform(Xtr2,Ytr2)\n",
    "    \n",
    "    #learn new lda\n",
    "    lda = LinearDiscriminantAnalysis()\n",
    "    lda.fit(Gtr, Ytr2)\n",
    "\n",
    "    # Apply on new test data\n",
    "    Gte = csp.transform(Xte)\n",
    "    #ldatest\n",
    "    acc = lda.score(Gte, Yte)\n",
    "    \n",
    "    # time\n",
    "    stop = timeit.default_timer()\n",
    "    time = stop - start\n",
    "    \n",
    "    return acc, time "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Sinkhorn_Transport(Gtr, Ytr, Gval, Yval, Gte, Yte, rango_e, metric, outerkfold, innerkfold, M):\n",
    "    \n",
    "    lda = LinearDiscriminantAnalysis()\n",
    "    \n",
    "    # Subset selection\n",
    "    G_FOTDAs_, Y_FOTDAs_, regu_FOTDAs_=\\\n",
    "    SelectSubsetTraining_OTDAs(Gtr, Ytr, Gval, Yval, rango_e, lda, metric, outerkfold, innerkfold, M)\n",
    "\n",
    "    #time\n",
    "    start = timeit.default_timer()\n",
    "    \n",
    "    Gtr_daot = G_FOTDAs_\n",
    "    Ytr_daot = Y_FOTDAs_ \n",
    "    \n",
    "    otda = ot.da.SinkhornTransport(metric=metric, reg_e=regu_FOTDAs_)\n",
    "    #learn the map\n",
    "    otda.fit(Xs=Gtr_daot, ys=Ytr_daot, Xt=Gval)\n",
    "    \n",
    "    #apply the mapping over source data\n",
    "    transp_Xs = otda.transform(Xs=Gtr)\n",
    "\n",
    "    # train a new classifier bases upon the transform source data\n",
    "    lda.fit(transp_Xs, Ytr)\n",
    "    \n",
    "    # Compute acc\n",
    "    yt_predict = lda.predict(Gte)\n",
    "    acc = accuracy_score(Yte, yt_predict)\n",
    "    \n",
    "    # time\n",
    "    stop = timeit.default_timer()\n",
    "    time = stop - start  \n",
    "    \n",
    "    return acc, time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def GroupLasso_Transport(Gtr, Ytr, Gval, Yval, Gte, Yte, rango_e, rango_cl, metric, outerkfold, innerkfold, M):\n",
    "    \n",
    "    lda = LinearDiscriminantAnalysis()\n",
    "    \n",
    "    # Subset selection\n",
    "    G_FOTDAl1l2_, Y_FOTDAl1l2_, regu_FOTDAl1l2_=\\\n",
    "    SelectSubsetTraining_OTDAl1l2(Gtr, Ytr, Gval, Yval, rango_e, rango_cl, lda, metric, outerkfold, innerkfold, M)\n",
    "    \n",
    "    #time\n",
    "    start = timeit.default_timer()\n",
    "    \n",
    "    Gtr_daot = G_FOTDAl1l2_\n",
    "    Ytr_daot = Y_FOTDAl1l2_\n",
    "    \n",
    "    otda = ot.da.SinkhornL1l2Transport(metric = metric ,reg_e = regu_FOTDAl1l2_[0], reg_cl = regu_FOTDAl1l2_[1])\n",
    "    otda.fit(Xs=Gtr_daot, ys=Ytr_daot, Xt=Gval)\n",
    "\n",
    "    #transport taget samples onto source samples\n",
    "    transp_Xs = otda.transform(Xs=Gtr)\n",
    "\n",
    "    # train a new classifier bases upon the transform source data\n",
    "    lda.fit(transp_Xs,Ytr)\n",
    "\n",
    "    # Compute acc\n",
    "    yt_predict = lda.predict(Gte)\n",
    "    acc = accuracy_score(Yte, yt_predict)\n",
    "    \n",
    "    # time\n",
    "    stop = timeit.default_timer()\n",
    "    time = stop - start \n",
    "        \n",
    "    \n",
    "    return acc, time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Backward_Sinkhorn_Transport(Gtr, Ytr, Gval, Yval, Gte, Yte, rango_e, lda, metric, outerkfold, innerkfold, M):\n",
    "    # the classifier already trained is an input of the function\n",
    "\n",
    "    # Subset selection\n",
    "    G_BOTDAs_, Y_BOTDAs_, regu_BOTDAs_=\\\n",
    "    SelectSubsetTraining_BOTDAs(Gtr, Ytr, Gval, Yval, rango_e, lda, metric, outerkfold, innerkfold, M)\n",
    "    \n",
    "    # time\n",
    "    start = timeit.default_timer()\n",
    "    \n",
    "    Gtr_botda = G_BOTDAs_\n",
    "    Ytr_botda = Y_BOTDAs_\n",
    "    \n",
    "    # Transport plan\n",
    "    botda = ot.da.SinkhornTransport(metric=metric, reg_e=regu_BOTDAs_)\n",
    "    botda.fit(Xs=Gval, ys=Yval, Xt=Gtr_botda)\n",
    "    \n",
    "    #transport testing samples\n",
    "    transp_Xt_backward = botda.transform(Xs=Gte)\n",
    "    \n",
    "    # Compute accuracy without retraining    \n",
    "    yt_predict = lda.predict(transp_Xt_backward)\n",
    "    acc = accuracy_score(Yte, yt_predict)\n",
    "    \n",
    "    # time\n",
    "    stop = timeit.default_timer()\n",
    "    time = stop - start\n",
    "    \n",
    "    return acc, time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Backward_GroupLasso_Transport(Gtr, Ytr, Gval, Yval, Gte, Yte, rango_e, rango_cl, lda, metric, outerkfold, innerkfold, M):\n",
    "    # the classifier already trained is an input of the function\n",
    "    \n",
    "    # Subset selection \n",
    "    G_BOTDAl1l2_, Y_BOTDAl1l2_, regu_BOTDAl1l2_=\\\n",
    "    SelectSubsetTraining_BOTDAl1l2(Gtr, Ytr, Gval, Yval, rango_e, rango_cl, lda, metric, outerkfold, innerkfold, M)\n",
    "    \n",
    "    #time\n",
    "    start = timeit.default_timer()\n",
    "    Gtr_botda = G_BOTDAl1l2_\n",
    "    Ytr_botda = Y_BOTDAl1l2_\n",
    "    \n",
    "    botda = ot.da.SinkhornL1l2Transport(metric=metric, reg_e=regu_BOTDAl1l2_[0], reg_cl=regu_BOTDAl1l2_[1])\n",
    "    botda.fit(Xs=Gval, ys=Yval, Xt=Gtr_botda)\n",
    "    \n",
    "    #transport testing samples\n",
    "    transp_Xt_backward=botda.transform(Xs=Gte)\n",
    "    \n",
    "    # Compute accuracy without retraining    \n",
    "    yt_predict = lda.predict(transp_Xt_backward)\n",
    "    acc = accuracy_score(Yte, yt_predict)\n",
    "    \n",
    "    # time\n",
    "    stop = timeit.default_timer()\n",
    "    time = stop - start\n",
    "    \n",
    "    \n",
    "    return acc, time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def RPA(Xtr,Xval,Xte,Ytr,Yval,Yte):\n",
    "    \n",
    "    # time\n",
    "    start = timeit.default_timer()\n",
    "    # cov matrix estimation\n",
    "    cov_tr = Covariances().transform(Xtr)\n",
    "    cov_val= Covariances().transform(Xval)\n",
    "    cov_te = Covariances().transform(Xte)\n",
    "        \n",
    "    clf = MDM()\n",
    "    source={'covs':cov_tr, 'labels': Ytr}\n",
    "    target_org_train={'covs':cov_val, 'labels': Yval}\n",
    "    target_org_test={'covs':cov_te, 'labels': Yte}\n",
    "    \n",
    "    # re-centered matrices\n",
    "    source_rct, target_rct_train, target_rct_test = TL.RPA_recenter(source, target_org_train, target_org_test)   \n",
    "    # stretched the re-centered matrices\n",
    "    source_rcs, target_rcs_train, target_rcs_test = TL.RPA_stretch(source_rct, target_rct_train, target_rct_test)\n",
    "    # rotate the re-centered-stretched matrices using information from classes\n",
    "    source_rpa, target_rpa_train, target_rpa_test = TL.RPA_rotate(source_rcs, target_rcs_train, target_rcs_test)\n",
    "    \n",
    "    # get data\n",
    "    covs_source, y_source = source_rpa['covs'], source_rpa['labels']\n",
    "    covs_target_train, y_target_train = target_rpa_train['covs'], target_rpa_train['labels']\n",
    "    covs_target_test, y_target_test = target_rpa_test['covs'], target_rpa_test['labels']\n",
    "    \n",
    "    # append train and validation data\n",
    "    covs_train = np.concatenate([covs_source, covs_target_train])\n",
    "    y_train = np.concatenate([y_source, y_target_train])\n",
    "    \n",
    "    # train\n",
    "    clf.fit(covs_train, y_train)\n",
    "    \n",
    "    # test\n",
    "    covs_test = covs_target_test\n",
    "    y_test = y_target_test\n",
    "    y_pred = clf.predict(covs_test)\n",
    "    \n",
    "    #acc\n",
    "    acc = accuracy_score(Yte, y_pred)\n",
    "    \n",
    "    # time\n",
    "    stop = timeit.default_timer()\n",
    "    time = stop - start\n",
    "    \n",
    "    return acc, time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def EU(Xtr,Xval,Xte,Ytr,Yval,Yte):\n",
    "    \n",
    "    # time\n",
    "    start = timeit.default_timer()\n",
    "    # Estimate single trial covariance\n",
    "    cov_tr = Covariances().transform(Xtr)\n",
    "    cov_val= Covariances().transform(Xval)\n",
    "    \n",
    "    Ctr = cov_tr.mean(0)\n",
    "    Cval = cov_val.mean(0)\n",
    "    \n",
    "    # aligment\n",
    "    Xtr_eu = np.asarray([np.dot(invsqrtm(Ctr), epoch) for epoch in Xtr])\n",
    "    Xval_eu = np.asarray([np.dot(invsqrtm(Cval), epoch) for epoch in Xval])\n",
    "    Xte_eu = np.asarray([np.dot(invsqrtm(Cval), epoch) for epoch in Xte])\n",
    "\n",
    "    # append train and validation data\n",
    "    x_train = np.concatenate([Xtr_eu, Xval_eu])\n",
    "    y_train = np.concatenate([Ytr, Yval])\n",
    "\n",
    "    # train new csp+lda\n",
    "    csp = CSP(n_components=6, reg='empirical', log=True, norm_trace=False, cov_est='epoch')\n",
    "    # learn csp filters\n",
    "    Gtr = csp.fit_transform(x_train,y_train)\n",
    "    \n",
    "    # learn lda\n",
    "    lda = LinearDiscriminantAnalysis()\n",
    "    lda.fit(Gtr,y_train)\n",
    "    \n",
    "    # test\n",
    "    Gte = csp.transform(Xte_eu)  \n",
    "    # acc\n",
    "    acc = lda.score(Gte, Yte)\n",
    "    # time\n",
    "    stop = timeit.default_timer()\n",
    "    time = stop - start\n",
    "        \n",
    "    return acc, time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load and filter data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "fName = 'Data/DataSession1_S9.mat'\n",
    "s = scipy.io.loadmat(fName)\n",
    "\n",
    "Data_S1=s[\"X\"]\n",
    "Labels_S1=s[\"y\"]\n",
    "Labels_S1=np.squeeze(Labels_S1)\n",
    "\n",
    "#filterting with mne\n",
    "[nt, nc, ns]=np.shape(Data_S1)\n",
    "Data_S1=np.reshape(Data_S1, [nt, nc*ns])\n",
    "Data_S1=mne.filter.filter_data(Data_S1, 128, 8, 30)\n",
    "Data_S1=np.reshape(Data_S1, [nt,nc,ns])\n",
    "\n",
    "fName = 'Data/DataSession2_S9.mat'\n",
    "s2 = scipy.io.loadmat(fName)\n",
    "\n",
    "Data_S2=s2[\"X\"]\n",
    "Labels_S2=s2[\"y\"]\n",
    "Labels_S2=np.squeeze(Labels_S2)\n",
    "\n",
    "#filterting with mne\n",
    "[nt, nc, ns]=np.shape(Data_S2)\n",
    "Data_S2=np.reshape(Data_S2, [nt, nc*ns])\n",
    "Data_S2=mne.filter.filter_data(Data_S2, 128, 8, 30)\n",
    "Data_S2=np.reshape(Data_S2, [nt,nc,ns])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Learn CSP+LDA from source data (Data_S1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LinearDiscriminantAnalysis(n_components=None, priors=None, shrinkage=None,\n",
       "                           solver='svd', store_covariance=False, tol=0.0001)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Xtr = Data_S1\n",
    "Ytr = Labels_S1\n",
    "csp = CSP(n_components=6, reg='empirical', log=True, norm_trace=False, cov_est='epoch')\n",
    "#learn csp filters\n",
    "Gtr = csp.fit_transform(Xtr, Ytr)\n",
    "#learn lda\n",
    "lda = LinearDiscriminantAnalysis()\n",
    "lda.fit(Gtr,Ytr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### For each run of 20 trials each, make the data adaptation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running testing RUN=0\n",
      "ACC\n",
      "{'sc': 0.55, 'sr': 0.55, 'ea': 0.7, 'fotda_s': 0.75, 'fotda_l1l2': 0.65, 'botda_s': 0.9, 'botda_l1l2': 0.9}\n",
      "CT\n",
      "{'sr': 2.256, 'rpa': 3.2, 'eu': 1.278, 'fotda_s': 0.012, 'fotda_l1l2': 0.118, 'botda_s': 0.006, 'botda_l1l2': 0.082}\n",
      "Running testing RUN=1\n",
      "ACC\n",
      "{'sc': 0.7, 'sr': 0.8, 'ea': 0.85, 'fotda_s': 0.8, 'fotda_l1l2': 0.8, 'botda_s': 0.75, 'botda_l1l2': 0.85}\n",
      "CT\n",
      "{'sr': 1.224, 'rpa': 2.571, 'eu': 1.577, 'fotda_s': 0.012, 'fotda_l1l2': 0.094, 'botda_s': 0.008, 'botda_l1l2': 0.08}\n",
      "Running testing RUN=2\n",
      "ACC\n",
      "{'sc': 0.65, 'sr': 0.75, 'ea': 0.7, 'fotda_s': 0.75, 'fotda_l1l2': 0.8, 'botda_s': 0.8, 'botda_l1l2': 0.8}\n",
      "CT\n",
      "{'sr': 0.949, 'rpa': 2.313, 'eu': 1.266, 'fotda_s': 0.008, 'fotda_l1l2': 0.212, 'botda_s': 0.01, 'botda_l1l2': 0.1}\n",
      "Running testing RUN=3\n",
      "ACC\n",
      "{'sc': 0.75, 'sr': 0.8, 'ea': 0.8, 'fotda_s': 0.8, 'fotda_l1l2': 0.8, 'botda_s': 0.8, 'botda_l1l2': 0.8}\n",
      "CT\n",
      "{'sr': 0.897, 'rpa': 2.809, 'eu': 1.343, 'fotda_s': 0.013, 'fotda_l1l2': 0.175, 'botda_s': 0.009, 'botda_l1l2': 0.137}\n",
      "Running testing RUN=4\n",
      "ACC\n",
      "{'sc': 0.95, 'sr': 0.8, 'ea': 0.95, 'fotda_s': 0.95, 'fotda_l1l2': 0.95, 'botda_s': 1.0, 'botda_l1l2': 0.95}\n",
      "CT\n",
      "{'sr': 0.892, 'rpa': 4.298, 'eu': 2.213, 'fotda_s': 0.016, 'fotda_l1l2': 0.319, 'botda_s': 0.018, 'botda_l1l2': 0.257}\n",
      "Running testing RUN=5\n",
      "ACC\n",
      "{'sc': 0.7, 'sr': 0.75, 'ea': 0.65, 'fotda_s': 0.7, 'fotda_l1l2': 0.7, 'botda_s': 0.65, 'botda_l1l2': 0.65}\n",
      "CT\n",
      "{'sr': 1.28, 'rpa': 3.592, 'eu': 1.577, 'fotda_s': 0.032, 'fotda_l1l2': 0.408, 'botda_s': 0.027, 'botda_l1l2': 0.355}\n",
      "Running testing RUN=6\n",
      "ACC\n",
      "{'sc': 0.75, 'sr': 0.65, 'ea': 0.65, 'fotda_s': 0.7, 'fotda_l1l2': 0.7, 'botda_s': 0.7, 'botda_l1l2': 0.65}\n",
      "CT\n",
      "{'sr': 0.79, 'rpa': 3.042, 'eu': 1.672, 'fotda_s': 0.006, 'fotda_l1l2': 0.499, 'botda_s': 0.019, 'botda_l1l2': 0.286}\n"
     ]
    }
   ],
   "source": [
    "for re in range(0,7):\n",
    "    print('Running testing RUN={:1.0f}'.format(re))\n",
    "    #testing run\n",
    "    Xte = Data_S2[0+20*(re+1):20*(re+1)+20]\n",
    "    Yte = Labels_S2[0+20*(re+1):20*(re+1)+20]\n",
    "    #transportation set-prior data\n",
    "    Xval = Data_S2[0:20*re+20]\n",
    "    Yval = Labels_S2[0:20*re+20]\n",
    "    \n",
    "    #feature computation\n",
    "    Gval = csp.transform(Xval)\n",
    "    Gte = csp.transform(Xte)\n",
    "    \n",
    "    M = len(Yval) #for the source subset selection\n",
    "    \n",
    "    # SC  \n",
    "    acc_sc, time_sc = SC(Gte, Yte, lda)\n",
    "    \n",
    "    # SR\n",
    "    acc_sr, time_sr = SR(Data_S2, Labels_S2, re, Xtr, Ytr, Xte, Yte)\n",
    "    \n",
    "    #%% # Sinkhorn Transport\n",
    "    acc_fotdas, time_fs = Sinkhorn_Transport(Gtr, Ytr, Gval, Yval, Gte, Yte, rango_e, metric, outerkfold, innerkfold, M)\n",
    "    \n",
    "    #%% # Group-Lasso Transport\n",
    "    acc_fotdal1l2, time_fg = GroupLasso_Transport(Gtr, Ytr, Gval, Yval, Gte, Yte, rango_e, rango_cl, metric, outerkfold, innerkfold, M)\n",
    "    \n",
    "    #%% # Backward Sinkhorn Transport\n",
    "    acc_botdas, time_bs = Backward_Sinkhorn_Transport(Gtr, Ytr, Gval, Yval, Gte, Yte, rango_e, lda, metric, outerkfold, innerkfold, M)\n",
    "    \n",
    "    #%% # Backward Group-Lasso Transport\n",
    "    acc_botdal1l2, time_bg = Backward_GroupLasso_Transport(Gtr, Ytr, Gval, Yval, Gte, Yte, rango_e, rango_cl, lda, metric, outerkfold, innerkfold, M)\n",
    "    \n",
    "    # Riemann\n",
    "    acc_rpa, time_rpa = RPA(Xtr, Xval, Xte, Ytr, Yval, Yte)\n",
    "    \n",
    "    # Euclidean\n",
    "    acc_eu, time_eu = EU(Xtr, Xval, Xte, Ytr, Yval, Yte)\n",
    "    \n",
    "    # print results\n",
    "    # accuracy\n",
    "    acc = {}\n",
    "    acc[\"sc\"] = acc_sc\n",
    "    acc[\"sr\"] = acc_sr\n",
    "    # acc[\"rpa\"] = acc_rpa\n",
    "    acc[\"ea\"] = acc_eu\n",
    "    acc[\"fotda_s\"] = acc_fotdas\n",
    "    acc[\"fotda_l1l2\"] = acc_fotdal1l2\n",
    "    acc[\"botda_s\"] = acc_botdas\n",
    "    acc[\"botda_l1l2\"] = acc_botdal1l2\n",
    "    \n",
    "    # computing time\n",
    "    time = {}\n",
    "    time[\"sr\"] = round(time_sr,3)\n",
    "    time[\"rpa\"] = round(time_rpa,3)\n",
    "    time[\"eu\"] = round(time_eu,3)\n",
    "    time[\"fotda_s\"] = round(time_fs,3)\n",
    "    time[\"fotda_l1l2\"] = round(time_fg,3)\n",
    "    time[\"botda_s\"] = round(time_bs,3)\n",
    "    time[\"botda_l1l2\"] = round(time_bg,3)\n",
    "    \n",
    "    print('ACC')\n",
    "    print(acc)\n",
    "    print('CT')\n",
    "    print(time)\n",
    "    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
